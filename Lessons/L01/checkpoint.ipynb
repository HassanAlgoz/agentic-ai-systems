{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54a9b404",
   "metadata": {},
   "source": [
    "# Short-term memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be35b9ec",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Memory is a system that remembers information about previous interactions. For AI agents, memory is crucial because it lets them remember previous interactions, learn from feedback, and adapt to user preferences. As agents tackle more complex tasks with numerous user interactions, this capability becomes essential for both efficiency and user satisfaction.\n",
    "\n",
    "Short term memory lets your application remember previous interactions within a single thread or conversation.\n",
    "\n",
    "\n",
    "::: {.callout-note}\n",
    "\n",
    "A **thread** organizes multiple interactions in a session, similar to the way email groups messages in a single conversation.\n",
    "\n",
    ":::\n",
    "\n",
    "Conversation history is the most common form of short-term memory. Long conversations pose a challenge to today's LLMs; a full history may not fit inside an LLM's context window, resulting in an context loss or errors.\n",
    "\n",
    "Even if your model supports the full context length, most LLMs still perform poorly over long contexts. They get \"distracted\" by stale or off-topic content, all while suffering from slower response times and higher costs.\n",
    "\n",
    "Chat models accept context using [messages](https://docs.langchain.com/oss/python/langchain/messages), which include instructions (a system message) and inputs (human messages). In chat applications, messages alternate between human inputs and model responses, resulting in a list of messages that grows longer over time. Because context windows are limited, many applications can benefit from using techniques to remove or \"forget\" stale information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b746fd50",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "To add short-term memory (thread-level persistence) to an agent, you need to specify a `checkpointer` when creating an agent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3102b943",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "\n",
    "LangChain's agent manages short-term memory as a part of your agent's state.\n",
    "\n",
    "By storing these in the graph's state, the agent can access the full context for a given conversation while maintaining separation between different threads.\n",
    "\n",
    "State is persisted to a database (or memory) using a checkpointer so the thread can be resumed at any time.\n",
    "\n",
    "Short-term memory updates when the agent is invoked or a step (like a tool call) is completed, and the state is read at the start of each step.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819b13fa",
   "metadata": {},
   "source": [
    "```python\n",
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    \"gpt-5-nano\",\n",
    "    tools=[get_user_info],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Hi! My name is Bob.\"}]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8c86bf",
   "metadata": {},
   "source": [
    "1. `checkpointer=InMemorySaver(),`\n",
    "2. `{\"configurable\": {\"thread_id\": \"1\"}},`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35314de",
   "metadata": {},
   "source": [
    "### In production\n",
    "\n",
    "In production, use a checkpointer backed by a database:\n",
    "\n",
    "```shell\n",
    "uv add langgraph-checkpoint-postgres\n",
    "```\n",
    "\n",
    "```python\n",
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "\n",
    "\n",
    "DB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\n",
    "with PostgresSaver.from_conn_string(DB_URI) as checkpointer:\n",
    "    checkpointer.setup() # auto create tables in PostgresSql\n",
    "    agent = create_agent(\n",
    "        \"gpt-5\",\n",
    "        tools=[get_user_info],\n",
    "        checkpointer=checkpointer,\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfd7e5e",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "For more checkpointer options including SQLite, Postgres, and Azure Cosmos DB, see the [list of checkpointer libraries](https://docs.langchain.com/oss/python/langgraph/persistence#checkpointer-libraries) in the Persistence documentation.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0936d3f8",
   "metadata": {},
   "source": [
    "## Customizing agent memory\n",
    "\n",
    "By default, agents use [`AgentState`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.AgentState) to manage short term memory, specifically the conversation history via a `messages` key.\n",
    "\n",
    "You can extend [`AgentState`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.AgentState) to add additional fields. Custom state schemas are passed to [`create_agent`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.create_agent) using the [`state_schema`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.AgentMiddleware.state_schema) parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080d01c3",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "\n",
    "class CustomAgentState(AgentState):\n",
    "    user_id: str\n",
    "    preferences: dict\n",
    "\n",
    "agent = create_agent(\n",
    "    \"gpt-5\",\n",
    "    tools=[get_user_info],\n",
    "    state_schema=CustomAgentState,  # [!code highlight]\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "# Custom state can be passed in invoke\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "        \"user_id\": \"user_123\",\n",
    "        \"preferences\": {\"theme\": \"dark\"}\n",
    "    },\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf28e76",
   "metadata": {},
   "source": [
    "## Common patterns\n",
    "\n",
    "With [short-term memory](#add-short-term-memory) enabled, long conversations can exceed the LLM's context window. Common solutions are:\n",
    "\n",
    "1. **Trim messages**: Remove first or last N messages (before calling LLM)\n",
    "2. **Delete messages**: Remove messages from LangGraph state permanently\n",
    "3. **Summarize messages**: Summarize earlier messages in the history and replace them with a summary\n",
    "4. **Custom strategies**: Custom strategies (e.g., message filtering, etc.)\n",
    "\n",
    "This allows the agent to keep track of the conversation without exceeding the LLM's context window.\n",
    "\n",
    "Checkout: [Common patterns](https://docs.langchain.com/oss/python/langchain/short-term-memory#common-patterns) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83c433d",
   "metadata": {},
   "source": [
    "## Access memory\n",
    "\n",
    "You can access and modify the short-term memory (state) of an agent in several ways:\n",
    "\n",
    "### Tools\n",
    "\n",
    "#### Read short-term memory in a tool\n",
    "\n",
    "Access short term memory (state) in a tool using the `runtime` parameter (typed as `ToolRuntime`).\n",
    "\n",
    "The `runtime` parameter is hidden from the tool signature (so the model doesn't see it), but the tool can access the state through it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce4aa22",
   "metadata": {},
   "source": [
    "```python\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "\n",
    "class CustomState(AgentState):\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def get_user_info(\n",
    "    runtime: ToolRuntime\n",
    ") -> str:\n",
    "    \"\"\"Look up user info.\"\"\"\n",
    "    user_id = runtime.state[\"user_id\"]\n",
    "    return \"User is John Smith\" if user_id == \"user_123\" else \"Unknown user\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-nano\",\n",
    "    tools=[get_user_info],\n",
    "    state_schema=CustomState,\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": \"look up user information\",\n",
    "    \"user_id\": \"user_123\"\n",
    "})\n",
    "print(result[\"messages\"][-1].content)\n",
    "# > User is John Smith.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6821e211",
   "metadata": {},
   "source": [
    "\n",
    "#### Write short-term memory from tools\n",
    "\n",
    "To modify the agent's short-term memory (state) during execution, you can return state updates directly from the tools.\n",
    "\n",
    "This is useful for persisting intermediate results or making information accessible to subsequent tools or prompts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e468c0",
   "metadata": {},
   "source": [
    "```python\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.messages import ToolMessage\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langgraph.types import Command\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class CustomState(AgentState):  # [!code highlight]\n",
    "    user_name: str\n",
    "\n",
    "class CustomContext(BaseModel):\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def update_user_info(\n",
    "    runtime: ToolRuntime[CustomContext, CustomState],\n",
    ") -> Command:\n",
    "    \"\"\"Look up and update user info.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    name = \"John Smith\" if user_id == \"user_123\" else \"Unknown user\"\n",
    "    return Command(update={  # [!code highlight]\n",
    "        \"user_name\": name,\n",
    "        # update the message history\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                \"Successfully looked up user information\",\n",
    "                tool_call_id=runtime.tool_call_id\n",
    "            )\n",
    "        ]\n",
    "    })\n",
    "\n",
    "@tool\n",
    "def greet(\n",
    "    runtime: ToolRuntime[CustomContext, CustomState]\n",
    ") -> str | Command:\n",
    "    \"\"\"Use this to greet the user once you found their info.\"\"\"\n",
    "    user_name = runtime.state.get(\"user_name\", None)\n",
    "    if user_name is None:\n",
    "       return Command(update={\n",
    "            \"messages\": [\n",
    "                ToolMessage(\n",
    "                    \"Please call the 'update_user_info' tool it will get and update the user's name.\",\n",
    "                    tool_call_id=runtime.tool_call_id\n",
    "                )\n",
    "            ]\n",
    "        })\n",
    "    return f\"Hello {user_name}!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-nano\",\n",
    "    tools=[update_user_info, greet],\n",
    "    state_schema=CustomState, # [!code highlight]\n",
    "    context_schema=CustomContext,\n",
    ")\n",
    "\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"greet the user\"}]},\n",
    "    context=CustomContext(user_id=\"user_123\"),\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
