---
title: "Introduction: What is Agentic AI?"
format: html
---

**Artificial Intelligence** is a field of Computer Science, studying how to automate decision making.

**Agentic AI** is where autonomy of the system is at the level of dealing not just with structured tabular data, but with unstructured data such as natural language, speech, visual to inform their decision, in a growingly less supervised manner; and hence, autonomous.

Specifically, today's Agentic AI systems are driven by **Large Language Models (LLMs)**.

## The Evolution of Agents from LLMs

**Large Language Models (LLMs)** are deep neural networks trained to model the most likely token given previous tokens.

First application was: **Translation**. Given an English sentence, the task is to generate the most likely Arabic equivalent. This is done word-by-word, by repeatedly predicting the next Arabic word, the original sentence plus all predicted words thus far.

This technique was able to scale thanks to the **Transformers** architecture which is based on the concept of **Attention**, which learns the influence each previous token has in generating the next token, in the translation.

Same concept applied more simply in **Paraphrasing**, **Summarization**, and even **Question-Answering**.

Trained on back-and-forth **Chat Conversations**, models were able to mimic chat-like interactions.

A hypothesis was proven at the time that **Multi-task Model** performs better than a single-task model. A more general idea is to train models to **"Follow Instructions"**. In which the user **Prompts** it to do any of the previously mentioned tasks, on-demand. Of course this needed lots of special *Data Curation*.

One task was especially important: **JSON mode**: in which models produced their output in json format, such that it can be parsed easily by programs.

Following that, an especially key development was the task of **Tool Calling**: in which a model is required to select from a set of Python funcition signatures (parameters, types, and docstrings) upon instruction. This is where **Agents** were born.

An **Agent** is based on an LLM in the following sequence:

- program takes input from user
- program feeds this input + available tools, into the LLM 
- **LLM generates** text parsable as a tool call
- program parses the tool call
- program executes the tool (function)
- program feeds the output to the LLM
- **LLM generates** output
- program prints this output to the user

### Choosing between models

Quality of models vary.

- Humans vote fairly for the best model on websites like [Arena.ai](https://arena.ai/).
- You can also compare pricing, providers, and usage tends on [OpenRouter.ai](https://openrouter.ai/models)
- An automatic short list models based on your priorities: [Model Recommendation | Artficial Analysis](https://artificialanalysis.ai/models/recommend)

## Applications of Agentic AI

What can Agentic AI do in the real-world? This question is best answered by looking at [Case Studies](https://docs.langchain.com/oss/python/langgraph/case-studies).

Also, reading the [State of Agent Engineering 2026](https://www.langchain.com/state-of-agent-engineering), a survey of 1,300 professionals — from engineers and product managers to business leaders and executives — to uncover the state of AI agents.

## Agent Framework

[LangChain](https://docs.langchain.com/oss/python/langchain/overview) organizes components into these main categories:

| Category                                                             | Purpose                     | Key Components                      | Use Cases                                          |
| -------------------------------------------------------------------- | --------------------------- | ----------------------------------- | -------------------------------------------------- |
| **[Models](https://docs.langchain.com/oss/python/langchain/models)**                           | AI reasoning and generation | Chat models, LLMs, Embedding models | Text generation, reasoning, semantic understanding |
| **[Tools](https://docs.langchain.com/oss/python/langchain/tools)**                             | External capabilities       | APIs, databases, etc.               | Web search, data access, computations              |
| **[Agents](https://docs.langchain.com/oss/python/langchain/agents)**                           | Orchestration and reasoning | ReAct agents, tool calling agents   | Nondeterministic workflows, decision making        |
| **[Memory](https://docs.langchain.com/oss/python/langchain/short-term-memory)**                | Context preservation        | Message history, custom state       | Conversations, stateful interactions               |
| **[Retrievers](https://docs.langchain.com/oss/python/integrations/retrievers)**                | Information access          | Vector retrievers, web retrievers   | RAG, knowledge base search                         |
| **[Document processing](https://docs.langchain.com/oss/python/integrations/document_loaders)** | Data ingestion              | Loaders, splitters, transformers    | PDF processing, web scraping                       |
| **[Vector Stores](https://docs.langchain.com/oss/python/integrations/vectorstores)**           | Semantic search             | Chroma, Pinecone, FAISS             | Similarity search, embeddings storage              |

Examples of other frameworks are:

- Vercel’s AI SDK
- CrewAI
- OpenAI Agents SDK
- Google ADK
- LlamaIndex

## Agent Runtime

Runtimes manage state, and state transitions (orchestration). In other words, building, managing, and deploying long-running, stateful agents. Concretely, things like:

* **Control-flow**: Step by step instructions, conditional execution, and loops.
* **Persistence**: Thread-level and cross-thread persistence for state management.
* **Durable execution**: Agents persist through failures and can run for extended periods, resuming from where they left off.
* **Streaming**: Support for streaming workflows and responses.
* **Human-in-the-loop**: Incorporate human oversight by inspecting and modifying agent state.

[LangGraph](https://docs.langchain.com/oss/python/langgraph/overview) builds and runs the flowchart..

### RAG (Retrieval-Augmented generation)

```{mermaid}
graph LR
    A[User question] --> B[Retriever]
    B --> C[Relevant docs]
    C --> D[Chat model]
    A --> D
    D --> E[Informed response]
```

### Agent with tools

```{mermaid}
graph LR
    A[User request] --> B[Agent]
    B --> C{Need tool?}
    C -->|Yes| D[Call tool]
    D --> E[Tool result]
    E --> B
    C -->|No| F[Final answer]
```

### Multi-agent system

```{mermaid}
graph LR
    A[Complex Task] --> B[Supervisor agent]
    B --> C[Specialist agent 1]
    B --> D[Specialist agent 2]
    C --> E[Results]
    D --> E
    E --> B
    B --> F[Coordinated response]
```

Other runtimes:

- Temporal
- Inngest

Note: for the best DX (Developer Experience), we will be using the **Functional API**.

## Agent Platform

**LangSmith**:

* **Deployment**: `localhost` -> production server
* **Observability**: tracing, real-time monitoring, alerting and usage.
* **Evaluation**: testing versions and providing feedback on traces.

## Key Takeways

- LangChain is the framework.
- LangGraph is the runtime.
- LangSmith is the platform.

---

- [Read More](https://docs.langchain.com/oss/python/concepts/products).
- [Help: Chat with langchain docs](https://chat.langchain.com/)